---
title: "Multiplayer fisherman game - Pilot results"
author: "Natalia Vélez, Kelsey Allen"
date: "August 27, 2016"
output: pdf_document
---

```{r setup, include=FALSE}
library(rjson)
library(plyr)
library(dplyr)
library(tidyr)
library(ggplot2)

```

## Human performance

n = 9 triads (26 unique subjects) participated in a coordination game. Each player represented a "fisherman," who had to silently coordinate with the other players to (1) catch fish, and (2) clear trees from the road in order to sell the fish in the market. Each player had a different "strength," corresponding to the number of fish they could catch *and* the number of trees they could clear from the road. (For example, a player with strength 2 could either clear 2 trees or catch 2 sacks of fish.)

Participants played through 24 scenarios of the fisherman game. Each scenario was presented on a screen through an online game written in jsPsych. In each scenario, participants would have a different strength (between 1-3) and there would be a different number of trees blocking the road (between 1-3). Each participant received two action cards (one with a fish, and the other with a tree) that they could use to indicate their action on each particular day. Participants responded on each trial by placing their action card face-down in the center of the table; once all participants indicated the response, the cards were revealed, and the experimenter logged their actions through the online interface. If participants did not converge on a solution in the first try, they repeated the same scenario.

Scenarios were generated by orthogonally varying each player's strength and the number of trees to create 80 unique scenarios. (One scenario, in which all players have a strength of 1 and there are 3 trees blocking the road, was not included.) Of these, 8 had 3 possible solutions—for example, if there are 3 trees blocking the road ($T = 3$) and each fisherman has a strength of 3 ($S(A) = S(B) = S(C) = 3$), any one of the players could have cleared the tree. All 8 of these scenarios were included in the trial order. Of the remaining scenarios, 33 had 1 possible solution (e.g., $S(A) = 1$, $S(B) = 2$, $S(C) = 3$, $T = 2$) and 39 had 2 possible solutions (e.g., $S(A) = 1$, $S(B) = 2$, $S(C) = 3$, $T = 3$). For each new game, 8 scenarios were randomly sampled from each category. Scenarios were presented in a pseudo-randomized order; the trials were arranged into scrambled blocks consisting of one scenariow with 1 solution, one with 2, and one with 3.

### Loading and cleaning up data
```{r Loading and cleaning up data}
scenario_info = fromJSON(file = 'scenarios.json')
data_files = list.files('pilot-results', pattern = '*.json')
fishing_data = NULL

# Helper function to find items in a list
lookup <- function(list, fun) {
  is_match = sapply(list, fun)
  return(which(is_match))
}

# Uses match_function to pull up information for each trial
match_scenario <- function(trees, strengths) {
  match_index = lookup(scenario_info, 
                       function (x) x$trees == trees && all(x$strengths == strengths))
  
  return(scenario_info[[match_index]])
}

for (f in 1:length(data_files)) {
  session_data = fromJSON(file = file.path('pilot-results', data_files[f]))
  
  for (trial in 1:length(session_data)) {
    trial_data = session_data[[trial]]
    num_trees = trial_data$trees
    strengths = trial_data$strengths
    n_solutions = match_scenario(num_trees, strengths)$n_solutions
    
    fishing_data = rbind.fill(fishing_data,
                         data.frame(
                           team = f,
                           trial_no = trial_data$num,
                           num_trees = num_trees,
                           p1_strength = strengths[1],
                           p2_strength = strengths[2],
                           p3_strength = strengths[3],
                           n_solutions = n_solutions,
                           p1_choice = trial_data$player_choices[1],
                           p2_choice = trial_data$player_choices[2],
                           p3_choice = trial_data$player_choices[3],
                           payoff = trial_data$payoff,
                           max_payoff = trial_data$max_payoff,
                           is_max = trial_data$is_max
                         ))
  }
}
```

## Performance
By request, I've counted the number of trials it took each group to finish the task. The 'best' group is the one that finished the whole task in the fewest tries (24 minimum).
```{r Best group}
team_identities = c('Mixed', 'Mixed', 'Mixed', 'Single', 'Single', 'Single', 'Mixed', 'Single', 'Single', 'Mixed')
team_identities = ifelse(team_identities == "Mixed", "Mixed gender", "Single gender")

best_group = fishing_data %>%
  group_by(team) %>%
  summarise(n_trials = length(trial_no)) %>%
  mutate(team_type = team_identities[team]) %>%
  arrange(n_trials)

gender_differences = best_group %>%
  group_by(team_type) %>%
  summarise(avg_time = mean(n_trials),
            se_time = se(n_trials))

ggplot(gender_differences, aes(x = team_type, y = avg_time, fill = team_type)) +
  geom_bar(stat = 'identity') +
  geom_errorbar(aes(ymin = avg_time - se_time, ymax = avg_time + se_time), width = 0.1) +
  guides(fill = F) +
  xlab('Team type') +
  ylab('Total number of attempts') +
  theme_bw(base_size = 18) +
  theme(axis.text = element_text(size = 18),
        axis.title = element_text(size = 18),
        legend.text = element_text(size = 18))
```

Now, below, here is a more fine-grained analysis of human performance. The plot generated at the end shows the average number of attempts, across all groups, for each type of trial on each block. (Remember: each block contains one of each kind of trial.)
```{r Performance summary}
se <- function(x){return(sd(x)/sqrt(length(x)))}

# Refactor raw data according to # of attempts
time_to_criterion = fishing_data %>%
  group_by(team, n_solutions, trial_no) %>%
  summarise(time_to_criterion = length(payoff)) %>%
  mutate(block = rank(trial_no)) %>%
  ungroup() %>%
  mutate(category = factor(n_solutions, label = c("One solution", "Two solutions", "Three solutions")),
         team = factor(team))

# Summarise time by category, block
time_by_block = time_to_criterion %>%
  group_by(block, category) %>%
  summarise(avg_time = mean(time_to_criterion),
            se_time = se(time_to_criterion))

ggplot(time_by_block, aes(x = block, y = avg_time, group = category, color = category)) +
  geom_point() +
  geom_line() +
  #geom_errorbar(aes(ymin = avg_time - se_time, ymax = avg_time + se_time), width = 0.1) +
  xlab("Block") +
  ylab("Number of attempts") +
  ggtitle("Human performance\nn = 10 triads (29 unique participants)") +
  theme_bw(base_size = 14) +
  theme(axis.text = element_text(size = 14),
        axis.title = element_text(size = 14),
        legend.text = element_text(size = 14)) +
  scale_color_manual("Trial type",
                     labels = c('One solution', 'Two solutions', 'Three solutions'),
                     values = c('#57b8dd', '#ecc110', '#d84f4f'))
```

Two things are apparent from this plot. First, scenarios that have three possible solutions are, overall, harder than those which two solutions, which are harder than those with one solution. Second, people get better at doing these (i.e., require fewer attempts to reach a good solution) over time. There is one puzzling bump in the beginning of the "One solution" curve that seems to go against these conclusions, but if we exclude one group who had trouble with task compliance, the "bump" goes away:

```{r Filtered results}
filtered_tbb = time_to_criterion %>%
  filter(team != 2) %>%
  group_by(block, category) %>%
  summarise(avg_time = mean(time_to_criterion),
            se_time = se(time_to_criterion))
  
ggplot(filtered_tbb, aes(x = block, y = avg_time, group = category, color = category)) +
  geom_point() +
  geom_line() +
  #geom_errorbar(aes(ymin = avg_time - se_time, ymax = avg_time + se_time), width = 0.1) +
  xlab("Block") +
  ylab("Number of attempts") +
  ggtitle("Human performance\nn = 9 triads (27 unique participants)") +
  theme_bw(base_size = 14) +
  theme(axis.text = element_text(size = 14),
        axis.title = element_text(size = 14),
        legend.text = element_text(size = 14)) +
  scale_color_manual("Trial type",
                     labels = c('One solution', 'Two solutions', 'Three solutions'),
                     values = c('#57b8dd', '#ecc110', '#d84f4f'))
```

To start, we want a model that at least mirrors human behavior in these respects.

So, how does our model do?

## Model performance

First, we'll load the results of our simulation:
```{r Load model data}
simulation_file = tail(list.files(pattern = 'simulation_results*'))
simulation_data = read.csv(simulation_file)
```

...And then we can do pretty much the same analyses that we did on the behavioral data:
```{r Model performance}
simulation_ttc = simulation_data %>%
  mutate(iteration = as.factor(iteration),
         n_solutions = as.factor(n_solutions),
         num = as.factor(num)) %>%
  group_by(iteration, n_solutions, num) %>%
  summarise(time_to_criterion = length(p1_action)) %>%
  mutate(block = rank(num)) 

simulation_by_block = simulation_ttc %>%
  group_by(n_solutions, block) %>%
  summarise(avg_time = mean(time_to_criterion),
            se_time = se(time_to_criterion))

ggplot(simulation_by_block, aes(x = block, y = avg_time, group = n_solutions, color = n_solutions)) +
  geom_point() +
  geom_line() +
  #geom_errorbar(aes(ymin = avg_time - se_time, ymax = avg_time + se_time), width = 0.1) +
  xlab("Block") +
  ylab("Number of attempts") +
  theme_bw(base_size = 14) +
  theme(axis.text = element_text(size = 14),
        axis.title = element_text(size = 14),
        legend.text = element_text(size = 14)) +
  scale_color_manual("Trial type",
                     labels = c('One solution', 'Two solutions', 'Three solutions'),
                     values = c('#57b8dd', '#ecc110', '#d84f4f')) +
  ggtitle('Model output\nalpha = 0.1, temperature = 2.5, depth = 0')
```